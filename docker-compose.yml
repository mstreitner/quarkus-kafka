services:
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092" # optional extra listener for tools
    environment:
      # KRaft mode (no Zookeeper)
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Single-node KRaft cluster id (any base64-ish 22 chars is fine)
      # If you want to regenerate: `docker run --rm confluentinc/cp-kafka:7.6.1 kafka-storage random-uuid`
      CLUSTER_ID: "Mw4wM2JjZTY2N2Y0NDc1Yz"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 20

  kafka-init-topics:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-init-topics
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["bash", "-lc"]
    command:
      - |
        set -euo pipefail
        echo "Creating topics (if missing)..."
        kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic example-input-v1 --partitions 1 --replication-factor 1
        kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic example-output-v1 --partitions 1 --replication-factor 1
        echo "Topics created."
    restart: "no"

  postgres:
    image: postgres:16
    container_name: apicurio-postgres
    hostname: apicurio-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: "registry"
      POSTGRES_USER: "registry"
      POSTGRES_PASSWORD: "registry"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U registry -d registry"]
      interval: 10s
      timeout: 5s
      retries: 30

  apicurio:
    image: apicurio/apicurio-registry:3.0.5
    container_name: apicurio
    hostname: apicurio
    ports:
      - "8082:8080"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      QUARKUS_HTTP_HOST: "0.0.0.0"
      # Use Postgres instead of the (unavailable) -mem image
      APICURIO_STORAGE_KIND: "sql"
      APICURIO_STORAGE_SQL_KIND: "postgresql"
      APICURIO_DATASOURCE_URL: "jdbc:postgresql://apicurio-postgres:5432/registry"
      APICURIO_DATASOURCE_USERNAME: "registry"
      APICURIO_DATASOURCE_PASSWORD: "registry"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/apis/registry/v3/system/info >/dev/null"]
      interval: 10s
      timeout: 5s
      retries: 30

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.6.1
    hostname: kafka-connect
    container_name: kafka-connect
    depends_on:
      kafka:
        condition: service_healthy
      apicurio:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"

      # Apicurio Registry (for Avro/Protobuf/JSON Schema converters)
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://apicurio:8080/apis/registry/v3"
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://apicurio:8080/apis/registry/v3"

    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8083/connectors >/dev/null"]
      interval: 10s
      timeout: 5s
      retries: 20

  kafbat-ui:
    image: ghcr.io/kafbat/kafka-ui:latest
    container_name: kafbat-ui
    depends_on:
      kafka:
        condition: service_healthy
      apicurio:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: "local"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9092"
      # NOTE: Kafbat UI expects Confluent Schema Registry endpoints (/subjects, /schemas/ids, ...).
      # Apicurio exposes those via its compatibility API (ccompat).
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: "http://apicurio:8080/apis/ccompat/v7"

networks:
  default:
    name: kafka-example

